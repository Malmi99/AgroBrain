# -*- coding: utf-8 -*-
"""Copy of Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bNR-DiuCg09usti93lAgIk_Fpedp2id0
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os
import pathlib
import numpy as np
from sklearn.metrics import confusion_matrix
import itertools

train_path_to_images = '/content/drive/MyDrive/soil_classification_dataset/Train/'
val_path_to_images = '/content/drive/MyDrive/soil_classification_dataset/Validation/'

import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# Set the path to the image file
img_path = '/content/drive/MyDrive/newdata_soil - Copy/Train/Strongly Alkaline/Red47.jpg'

# Read the image using OpenCV
img = cv2.imread(img_path)

# Check if the image is valid
if img is None:
    print('Error: Could not read image file', img_path)
else:
    # Resize the image to a smaller size
    img_resized = cv2.resize(img, (400, 400))

    # Crop a region of interest (ROI) from the image
    x, y, w, h = 100, 100, 200, 200
    img_cropped = img[y:y+h, x:x+w]

    # Convert the image to grayscale
    img_gray = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)

    # Apply histogram equalization to enhance contrast
    img_enhanced = cv2.equalizeHist(img_gray)

    # Threshold the enhanced image to obtain a binary image
    ret, img_thresh = cv2.threshold(img_enhanced, 127, 255, cv2.THRESH_BINARY)

    # Display the original and processed images
    cv2_imshow(img)
    cv2_imshow(img_resized)
    cv2_imshow(img_cropped)
    cv2_imshow(img_gray)
    cv2_imshow(img_enhanced)
    cv2_imshow(img_thresh)

train_data_dir = pathlib.Path(train_path_to_images)
train_class_names = np.array(sorted([item.name for item in train_data_dir.glob('*')]))
print(len(train_class_names))
print(train_class_names)

val_data_dir = pathlib.Path(val_path_to_images)
val_class_names = np.array(sorted([item.name for item in val_data_dir.glob('*')]))
print(len(val_class_names))
print(val_class_names)

# counting the number of images in each class directory for both the training and validation sets of a computer vision dataset.
train_num_img_class = []
for class_name in train_class_names:

  path_to_class = train_path_to_images + class_name
  class_dir = pathlib.Path(path_to_class)
  train_num_img_class.append(len([item.name for item in class_dir.glob('*')]))


val_num_img_class = []
for class_name in val_class_names:

  path_to_class = val_path_to_images + class_name
  class_dir = pathlib.Path(path_to_class)
  val_num_img_class.append(len([item.name for item in class_dir.glob('*')]))

# obtain the indices of the classes in the training and validation sets, sorted in ascending order of the number of images in each class.
arg_sorted_class_img_by_len_train = np.argsort(np.array(train_num_img_class))
arg_sorted_class_img_by_len_val = np.argsort(np.array(val_num_img_class))

# printing out the number of images in each class of the training and validation sets, sorted in ascending order of the number of images in each class.
for i in arg_sorted_class_img_by_len_train:
  print(f'{train_num_img_class[i]:5} {train_class_names[i]}')

for i in arg_sorted_class_img_by_len_val:
  print(f'{val_num_img_class[i]:5} {val_class_names[i]}')

# randomly selects and displays an image from a specified directory and class.
def view_random_images(target_dir, target_class):

    target_folder = target_dir + target_class

    random_image = random.sample(os.listdir(target_folder), 1)
    print(random_image)

    img = mpimg.imread(target_folder+ '//' + random_image[0])
    plt.imshow(img)
    plt.title(target_class)
    plt.axis('off')
    plt.show()

    print(f'image shape : {img.shape}')

# view_random_images(target_dir= train_path_to_images, target_class='Neutral')
# view_random_images(target_dir= train_path_to_images, target_class='Slightly Acidic')

# data augmentation and generates training and validation data sets using these generators
datagen = ImageDataGenerator(
        rescale = 1./255,
        shear_range = 0.2,
        zoom_range = 0.2,
        horizontal_flip = True
        )

train_data_set = datagen.flow_from_directory(
        train_data_dir,
        target_size=(255, 255),
        batch_size=64,
        shuffle=True,
        class_mode='categorical')

val_data_set = datagen.flow_from_directory(
        val_data_dir,
        target_size=(255, 255),
        batch_size=64,
        shuffle=True,
        class_mode='categorical')

def create_model():
  model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=64, kernel_size=5, activation="relu", input_shape=(255, 255, 3)),
    tf.keras.layers.MaxPool2D(pool_size=5),
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation="relu"),
    tf.keras.layers.MaxPool2D(pool_size=3),
    tf.keras.layers.Conv2D(filters=16, kernel_size=2, activation="relu"),
    tf.keras.layers.MaxPool2D(pool_size=2),
    tf.keras.layers.Conv2D(filters=8, kernel_size=2, activation="relu"),
    tf.keras.layers.MaxPool2D(pool_size=2),
    tf.keras.layers.Conv2D(filters=4, kernel_size=2, activation="relu"),
    tf.keras.layers.MaxPool2D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(5, activation="softmax")
  ])

  model.compile(optimizer='Adam',
              loss="categorical_crossentropy",
              metrics=["accuracy"])
  
  return model

cnn = create_model()

device_name = tf.test.gpu_device_name()
print('Found GPU at: {}'.format(device_name))

# model is assigned to the variable cnn.
with tf.device('/device:GPU:0'):
  history = cnn.fit(train_data_set,epochs=55,validation_data=val_data_set)

import pandas as pd

fig, ax = plt.subplots(1, figsize=(10,5))
ax.plot(history.epoch, history.history['accuracy'], 'b--o', label='accuracy')
ax.plot(history.epoch, history.history['loss'], 'r--o',label='loss')

ax.legend()
ax.grid()

ax.set_xlabel('epoch')
ax.set_ylabel('')

ax.set_title('Model training history')
plt.show()

cnn.save('//content//drive//MyDrive//Colab Notebooks//model//soil2.h5')

model = create_model()
model.load_weights('//content//drive//MyDrive//Colab Notebooks//model//soil2.h5')

from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True)

model.summary()

img_paths = train_data_set.filenames
predictions = []

for img_path in img_paths:

  full_path_to_img = train_path_to_images + img_path
  img = tf.keras.utils.load_img(
      full_path_to_img, grayscale=False, color_mode='rgb', target_size=[255, 255],
      interpolation='nearest'
  )
  input_arr = tf.keras.preprocessing.image.img_to_array(img)
  input_arr = np.array([input_arr])  # Convert single image to a batch.
  input_arr = input_arr / 255
  predictions.append(np.argmax(model.predict(input_arr)))

true_labels = train_data_set.labels

error_label_count = 0

for i in range(len(true_labels)):
  if true_labels[i] != predictions[i]:
    error_label_count+=1

train_accuracy = 100*(1-(error_label_count/len(true_labels)))
print("Train accuracy: {:5.2f}%".format(train_accuracy))

def displayConfusionMatrix(y_true, y_pred, classes=None, text_size=10, figsize = (20, 10)):

    cm = confusion_matrix(y_true, y_pred)
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    n_classes = cm.shape[0]

    fig, ax = plt.subplots(figsize=figsize)
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)

    if classes:
        labels = classes
    else:
        labels = np.arange(cm.shape[0])

    ax.set(
        title='Confusion Matrix',
        xlabel='Predicted Labels',
        ylabel='True Labels',
        xticks=np.arange(n_classes),
        yticks=np.arange(n_classes),
        xticklabels=labels,
        yticklabels=labels,
        )

    ax.xaxis.set_label_position('bottom')
    ax.xaxis.tick_bottom()

    ax.xaxis.label.set_size(text_size)
    ax.yaxis.label.set_size(text_size)
    ax.title.set_size(text_size)

    threshold = (cm.max() + cm.min()) / 2.0

    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, f'{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)', 
        horizontalalignment='center', 
        color='white' if cm[i, j] > threshold else 'black',
        size=text_size)


displayConfusionMatrix(train_data_set.labels, predictions, ['Neutral','Slightly Acidic','Slightly Alkaline','Strongly Acidic','Strongly Alkaline'])

import tensorflow as tf
import cv2
import numpy as np
import random
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

def prediction_probability_label(model, img_path, class_labels, is_rgb=True)->tuple:
  if is_rgb:
    img = tf.keras.utils.load_img(
                img_path, color_mode='rgb', target_size=[255, 255],
                interpolation='nearest'
            )
  else:
            img = tf.keras.utils.load_img(
                img_path, color_mode='grayscale', target_size=[255, 255],
                interpolation='nearest'
            )

  input_arr = tf.keras.preprocessing.image.img_to_array(img)
  input_arr = np.array([input_arr])  # Convert single image to a batch.
  input_arr = input_arr / 255
  pred_probs = model.predict(input_arr)[0]

  pred_class = np.argmax(pred_probs)
  pred_label = class_labels[pred_class]
  pred_prob = round(pred_probs[pred_class]*100, 2)


  return (pred_label, pred_prob)

newmodel = tf.keras.models.load_model('//content//drive//MyDrive//Colab Notebooks//model//soil2.h5')

# Set the path to the image file
img_path = '/content/drive/MyDrive/soil_classification_dataset/Train/Slightly Alkaline/1.jpg'

# Read the image using OpenCV
img = cv2.imread(img_path)

# Check if the image is valid
if img is None:
    print('Error: Could not read image file', img_path)
else:
    # Resize the image to a smaller size
    img_resized = cv2.resize(img, (400, 400))

    # Crop a region of interest (ROI) from the image
    x, y, w, h = 100, 100, 200, 200
    img_cropped = img[y:y+h, x:x+w]

    # Convert the image to grayscale
    img_gray = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)

    # Threshold the grayscale image to obtain a binary image
    ret, img_thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)

    # Display the original and processed images
    cv2_imshow(img)
    cv2_imshow(img_resized)
    cv2_imshow(img_cropped)
    cv2_imshow(img_gray)
    cv2_imshow(img_thresh)
class_labels = ['Neutral', 'Slightly Acidic', 'Slightly Alkaline' , 'Strongly Acidic','Strongly Alkaline'];

prediction_probability_label(newmodel, img_path, class_labels)